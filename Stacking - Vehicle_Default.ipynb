{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from scipy import sparse as ssp\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import datasets, linear_model, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(233154, 41)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(345546, 41)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(345546, 40)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Path = \"C:\\\\Users\\\\Himanshu\\\\Downloads\\\\train_aox2Jxw\\\\\"\n",
    "train_file = \"train.csv\"\n",
    "test_file =\"test_bqCt9Pv.csv\"\n",
    "\n",
    "train_df = pd.read_csv(Path+train_file)\n",
    "test_df = pd.read_csv(\"C:\\\\Users\\\\Himanshu\\\\Downloads\\\\\"+test_file)\n",
    "display(train_df.shape)\n",
    "test_df['loan_default']=0\n",
    "data = pd.concat([train_df, test_df])\n",
    "print(data.shape)\n",
    "data.drop(columns= ['loan_default'], inplace= True)\n",
    "display(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Function to convert a Yrs b months to months\"\"\"\n",
    "def total_months(x):\n",
    "    l =[]\n",
    "    l.append(x.split(' '))\n",
    "    return int(l[0][0][0])*12 + int(l[0][1][0])\n",
    "\n",
    "def variable_cleaning(data):\n",
    "    \n",
    "    \"\"\"Taking logarithmic transformations of variables to make the algorithm converge \"\"\"\n",
    "  \n",
    "    data['PERFORM_CNS.SCORE.DESCRIPTION'] = data['PERFORM_CNS.SCORE.DESCRIPTION'].replace('No Bureau History Available', 0)\n",
    "    data['PERFORM_CNS.SCORE.DESCRIPTION'] = data['PERFORM_CNS.SCORE.DESCRIPTION'].replace('Not Scored: Sufficient History Not Available', 0)\n",
    "    data['PERFORM_CNS.SCORE.DESCRIPTION'] = data['PERFORM_CNS.SCORE.DESCRIPTION'].replace('Not Scored: Not Enough Info available on the customer', 0)\n",
    "    data['PERFORM_CNS.SCORE.DESCRIPTION'] = data['PERFORM_CNS.SCORE.DESCRIPTION'].replace('Not Scored: No Activity seen on the customer (Inactive)',0)\n",
    "    data['PERFORM_CNS.SCORE.DESCRIPTION'] = data['PERFORM_CNS.SCORE.DESCRIPTION'].replace('Not Scored: No Updates available in last 36 months', 0)\n",
    "    data['PERFORM_CNS.SCORE.DESCRIPTION'] = data['PERFORM_CNS.SCORE.DESCRIPTION'].replace('Not Scored: Only a Guarantor', 0)\n",
    "    data['PERFORM_CNS.SCORE.DESCRIPTION'] = data['PERFORM_CNS.SCORE.DESCRIPTION'].replace('Not Scored: More than 50 active Accounts found',0)\n",
    "    data['PERFORM_CNS.SCORE.DESCRIPTION'] = data['PERFORM_CNS.SCORE.DESCRIPTION'].replace('M-Very High Risk', 1)\n",
    "    data['PERFORM_CNS.SCORE.DESCRIPTION'] = data['PERFORM_CNS.SCORE.DESCRIPTION'].replace('L-Very High Risk', 1)\n",
    "    data['PERFORM_CNS.SCORE.DESCRIPTION'] = data['PERFORM_CNS.SCORE.DESCRIPTION'].replace('K-High Risk', 2)\n",
    "    data['PERFORM_CNS.SCORE.DESCRIPTION'] = data['PERFORM_CNS.SCORE.DESCRIPTION'].replace('J-High Risk', 2)\n",
    "    data['PERFORM_CNS.SCORE.DESCRIPTION'] = data['PERFORM_CNS.SCORE.DESCRIPTION'].replace('I-Medium Risk', 3)\n",
    "    data['PERFORM_CNS.SCORE.DESCRIPTION'] = data['PERFORM_CNS.SCORE.DESCRIPTION'].replace('H-Medium Risk', 3)\n",
    "    data['PERFORM_CNS.SCORE.DESCRIPTION'] = data['PERFORM_CNS.SCORE.DESCRIPTION'].replace('G-Low Risk', 4)\n",
    "    data['PERFORM_CNS.SCORE.DESCRIPTION'] = data['PERFORM_CNS.SCORE.DESCRIPTION'].replace('F-Low Risk', 4)\n",
    "    data['PERFORM_CNS.SCORE.DESCRIPTION'] = data['PERFORM_CNS.SCORE.DESCRIPTION'].replace('E-Low Risk', 4)\n",
    "    data['PERFORM_CNS.SCORE.DESCRIPTION'] = data['PERFORM_CNS.SCORE.DESCRIPTION'].replace('D-Very Low Risk', 5)\n",
    "    data['PERFORM_CNS.SCORE.DESCRIPTION'] = data['PERFORM_CNS.SCORE.DESCRIPTION'].replace('C-Very Low Risk', 5)\n",
    "    data['PERFORM_CNS.SCORE.DESCRIPTION'] = data['PERFORM_CNS.SCORE.DESCRIPTION'].replace('B-Very Low Risk', 5)\n",
    "    data['PERFORM_CNS.SCORE.DESCRIPTION'] = data['PERFORM_CNS.SCORE.DESCRIPTION'].replace('A-Very Low Risk', 5)\n",
    "    \n",
    "        \n",
    "    data['Converted_AVERAGE.ACCT.AGE'] = train_df['AVERAGE.ACCT.AGE'].apply(total_months)\n",
    "    data['Converted_CREDIT.HISTORY.LENGTH'] = train_df['CREDIT.HISTORY.LENGTH'].apply(total_months)\n",
    "    \n",
    "    \n",
    "    data['Employment_ind'] = data['Employment.Type'].apply(lambda x: (1 if x == 'Self employed' else (0 if x == 'Salaried' else -1)))\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def creating_direct_variables(train_df, test_df):\n",
    "    \n",
    "    # 1. Age at loan disbursal date\n",
    "\n",
    "    train_df['Date.of.Birth'] = pd.to_datetime(train_df['Date.of.Birth'].values)\n",
    "    train_df['DisbursalDate'] = pd.to_datetime(train_df['DisbursalDate'].values)\n",
    "    train_df['Age_at_disbursaldate'] = (train_df['DisbursalDate'].dt.date - train_df['Date.of.Birth'].dt.date)/ np.timedelta64(365, 'D')\n",
    "\n",
    "    test_df['Date.of.Birth'] = pd.to_datetime(test_df['Date.of.Birth'].values)\n",
    "    test_df['DisbursalDate'] = pd.to_datetime(test_df['DisbursalDate'].values)\n",
    "    test_df['Age_at_disbursaldate'] = (test_df['DisbursalDate'].dt.date - test_df['Date.of.Birth'].dt.date)/ np.timedelta64(365, 'D')\n",
    "    \n",
    "    # 2. Total number of verified identities\n",
    "\n",
    "    train_df['Total_verification_flags'] = (train_df['Aadhar_flag'] + train_df['PAN_flag']+ train_df['VoterID_flag'] \\\n",
    "                                        +train_df['Driving_flag'] + train_df['Passport_flag'])\n",
    "    \n",
    "    test_df['Total_verification_flags'] = (test_df['Aadhar_flag'] + test_df['PAN_flag']+ test_df['VoterID_flag'] \\\n",
    "                                        +test_df['Driving_flag'] + test_df['Passport_flag'])\n",
    "\n",
    "    # 3. Disbursal Date and Month\n",
    "    \n",
    "    train_df['Disbursal_Month'] = train_df['DisbursalDate'].dt.month\n",
    "    train_df['Disbursal_Day'] = train_df['DisbursalDate'].dt.day\n",
    "\n",
    "    test_df['Disbursal_Month'] = test_df['DisbursalDate'].dt.month\n",
    "    test_df['Disbursal_Day'] = test_df['DisbursalDate'].dt.day \n",
    "    \n",
    "    # 4. PAn and Voter Id combo\n",
    "    \n",
    "    train_df.loc[((train_df['VoterID_flag'] == 0) & (train_df['PAN_flag'] == 0)),'VoterId_Pan_flag_Combo'] = 1\n",
    "    train_df.loc[((train_df['VoterID_flag'] == 0) & (train_df['PAN_flag'] == 1)),'VoterId_Pan_flag_Combo'] = 2\n",
    "    train_df.loc[((train_df['VoterID_flag'] == 1) & (train_df['PAN_flag'] == 0)),'VoterId_Pan_flag_Combo'] = 3\n",
    "    train_df.loc[((train_df['VoterID_flag'] == 1) & (train_df['PAN_flag'] == 1)),'VoterId_Pan_flag_Combo'] = 4\n",
    "\n",
    "\n",
    "    test_df.loc[((test_df['VoterID_flag'] == 0) & (test_df['PAN_flag'] == 0)),'VoterId_Pan_flag_Combo'] = 1\n",
    "    test_df.loc[((test_df['VoterID_flag'] == 0) & (test_df['PAN_flag'] == 1)),'VoterId_Pan_flag_Combo'] = 2\n",
    "    test_df.loc[((test_df['VoterID_flag'] == 1) & (test_df['PAN_flag'] == 0)),'VoterId_Pan_flag_Combo'] = 3\n",
    "    test_df.loc[((test_df['VoterID_flag'] == 1) & (test_df['PAN_flag'] == 1)),'VoterId_Pan_flag_Combo'] = 4\n",
    "\n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_dfg_variables(train_df,val,test_df):\n",
    "    # 5. Creating default to gross variables\n",
    "    \n",
    "    \n",
    "    df_supplier_id_ftg      = pd.DataFrame(train_df.groupby('supplier_id')['loan_default'].apply(lambda x: x.sum()/x.count() if x.count() >=20 else 0)).rename(columns = {'loan_default': 'supplier_id_ftg'})\n",
    "    df_branch_id_ftg        = pd.DataFrame(train_df.groupby('branch_id')['loan_default'].apply(lambda x: x.sum()/x.count() if x.count() >=20 else 0)).rename(columns = {'loan_default': 'branch_id_ftg'})\n",
    "    df_manufacturer_id_ftg  = pd.DataFrame(train_df.groupby('manufacturer_id')['loan_default'].apply(lambda x: x.sum()/x.count() if x.count() >=20 else 0)).rename(columns = {'loan_default': 'manufacturer_id_ftg'})\n",
    "    df_pincode_id_ftg       = pd.DataFrame(train_df.groupby('Current_pincode_ID')['loan_default'].apply(lambda x: x.sum()/x.count() if x.count() >=20  else 0)).rename(columns = {'loan_default': 'pincode_id_ftg'})\n",
    "    df_state_id_ftg         = pd.DataFrame(train_df.groupby('State_ID')['loan_default'].apply(lambda x: x.sum()/x.count() if x.count() >=20  else 0)).rename(columns = {'loan_default': 'state_id_ftg'})\n",
    "    df_employee_code_id_ftg = pd.DataFrame(train_df.groupby('Employee_code_ID')['loan_default'].apply(lambda x: x.sum()/x.count() if x.count() >=20 else 0)).rename(columns = {'loan_default': 'employee_code_id_ftg'})\n",
    "    df_combo_state_pin_ftg = pd.DataFrame(train_df.groupby(['State_ID','Current_pincode_ID'])['loan_default']\\\n",
    "                                          .apply(lambda x: x.sum()/x.count() if x.count() >=20 else 0))\\\n",
    "                                            .rename(columns = {'loan_default': 'state_pin_code_ftg'})\n",
    "    \n",
    "    train_df['supplier_id_ftg'] = df_supplier_id_ftg.loc[train_df.supplier_id ,'supplier_id_ftg'].values\n",
    "    train_df['branch_id_ftg'] = df_branch_id_ftg.loc[train_df.branch_id ,'branch_id_ftg'].values\n",
    "    train_df['manufacturer_id_ftg'] = df_manufacturer_id_ftg.loc[train_df.manufacturer_id ,'manufacturer_id_ftg'].values\n",
    "    train_df['pincode_id_ftg'] = df_pincode_id_ftg.loc[train_df.Current_pincode_ID ,'pincode_id_ftg'].values\n",
    "    train_df['state_id_ftg'] = df_state_id_ftg.loc[train_df.State_ID ,'state_id_ftg'].values\n",
    "    train_df['employee_code_id_ftg'] = df_employee_code_id_ftg.loc[train_df.Employee_code_ID ,'employee_code_id_ftg'].values\n",
    "    train_df['state_pin_code_ftg'] = df_combo_state_pin_ftg.loc[ (train_df.State_ID == df_combo_state_pin_ftg.index.get_level_values(0)) & \\\n",
    "                            (train_df.Current_pincode_ID == df_combo_state_pin_ftg.index.get_level_values(1)),'state_pin_code_ftg'].values\n",
    "\n",
    "    val['supplier_id_ftg'] = df_supplier_id_ftg.loc[val.supplier_id ,'supplier_id_ftg'].values\n",
    "    val['branch_id_ftg'] = df_branch_id_ftg.loc[val.branch_id ,'branch_id_ftg'].values\n",
    "    val['manufacturer_id_ftg'] = df_manufacturer_id_ftg.loc[val.manufacturer_id ,'manufacturer_id_ftg'].values\n",
    "    val['pincode_id_ftg'] = df_pincode_id_ftg.loc[val.Current_pincode_ID ,'pincode_id_ftg'].values\n",
    "    val['state_id_ftg'] = df_state_id_ftg.loc[val.State_ID ,'state_id_ftg'].values\n",
    "    val['employee_code_id_ftg'] = df_employee_code_id_ftg.loc[val.Employee_code_ID ,'employee_code_id_ftg'].values\n",
    "    val['state_pin_code_ftg'] = df_combo_state_pin_ftg.loc[(val.State_ID == \\\n",
    "                                  df_combo_state_pin_ftg.index.get_level_values(0)) &\\\n",
    "                            (val.Current_pincode_ID == df_combo_state_pin_ftg.index.get_level_values(1)),'state_pin_code_ftg'].values\n",
    "\n",
    "\n",
    "    test_df['supplier_id_ftg'] = df_supplier_id_ftg.loc[test_df.supplier_id ,'supplier_id_ftg'].values\n",
    "    test_df['branch_id_ftg'] = df_branch_id_ftg.loc[test_df.branch_id ,'branch_id_ftg'].values\n",
    "    test_df['manufacturer_id_ftg'] = df_manufacturer_id_ftg.loc[test_df.manufacturer_id ,'manufacturer_id_ftg'].values\n",
    "    test_df['pincode_id_ftg'] = df_pincode_id_ftg.loc[test_df.Current_pincode_ID ,'pincode_id_ftg'].values\n",
    "    test_df['state_id_ftg'] = df_state_id_ftg.loc[test_df.State_ID ,'state_id_ftg'].values\n",
    "    test_df['employee_code_id_ftg'] = df_employee_code_id_ftg.loc[test_df.Employee_code_ID ,'employee_code_id_ftg'].values\n",
    "    test_df['state_pin_code_ftg'] = df_combo_state_pin_ftg.loc[(test_df.State_ID == \\\n",
    "                                  df_combo_state_pin_ftg.index.get_level_values(0)) &\\\n",
    "                            (test_df.Current_pincode_ID == df_combo_state_pin_ftg.index.get_level_values(1)),'state_pin_code_ftg'].values\n",
    "\n",
    "\n",
    "    \n",
    "    return train_df,val,test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'learning_rate': 0.01,\n",
    "    'num_leaves': 255,  \n",
    "    'max_depth': 7,  \n",
    "    'min_child_samples':50,  \n",
    "    'max_bin': 100,  \n",
    "    'subsample': 0.7,  \n",
    "    'subsample_freq': 1,  \n",
    "    'colsample_bytree': 0.7,  \n",
    "    'min_child_weight': 0,  \n",
    "    'subsample_for_bin': 200,  \n",
    "    'min_split_gain': 0,  \n",
    "    'reg_alpha': 1,  \n",
    "    'reg_lambda': 1,  \n",
    "   # 'nthread': 8,\n",
    "    'verbose': 5,\n",
    "    'scale_pos_weight':99 \n",
    "    }\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = variable_cleaning(train_df)\n",
    "test_df = variable_cleaning(test_df)\n",
    "\n",
    "train_df, test_df = creating_direct_variables(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n : 0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Lengths must match to compare",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-f9d57599964e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreating_dfg_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrn_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     trn_data = lgb.Dataset(train[features],\n",
      "\u001b[1;32m<ipython-input-17-f001b9184f82>\u001b[0m in \u001b[0;36mcreating_dfg_variables\u001b[1;34m(train_df, val, test_df)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'state_id_ftg'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_state_id_ftg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mState_ID\u001b[0m \u001b[1;33m,\u001b[0m\u001b[1;34m'state_id_ftg'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'employee_code_id_ftg'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_employee_code_id_ftg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEmployee_code_ID\u001b[0m \u001b[1;33m,\u001b[0m\u001b[1;34m'employee_code_id_ftg'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'state_pin_code_ftg'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_combo_state_pin_ftg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mState_ID\u001b[0m \u001b[1;33m==\u001b[0m                                   \u001b[0mdf_combo_state_pin_ftg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m                            \u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCurrent_pincode_ID\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mdf_combo_state_pin_ftg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'state_pin_code_ftg'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mval\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'supplier_id_ftg'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_supplier_id_ftg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msupplier_id\u001b[0m \u001b[1;33m,\u001b[0m\u001b[1;34m'supplier_id_ftg'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, other, axis)\u001b[0m\n\u001b[0;32m   1251\u001b[0m             \u001b[1;31m# as it will broadcast\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1252\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1253\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Lengths must match to compare'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1255\u001b[0m             \u001b[0mres_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Lengths must match to compare"
     ]
    }
   ],
   "source": [
    "# Doing K fold crossvalidation\n",
    "\n",
    "NFOLDS = 5\n",
    "folds = StratifiedKFold(n_splits= NFOLDS, shuffle=True, random_state=218)\n",
    "all_f = train_df.columns\n",
    "features = ['disbursed_amount', 'asset_cost', 'ltv', 'Aadhar_flag', 'PAN_flag', 'VoterID_flag',\\\n",
    "                'Driving_flag', 'Passport_flag', 'PERFORM_CNS.SCORE', 'PRI.NO.OF.ACCTS', 'PRI.ACTIVE.ACCTS', 'PRI.OVERDUE.ACCTS',\n",
    "                'PRI.CURRENT.BALANCE', 'PRI.SANCTIONED.AMOUNT', 'PRI.DISBURSED.AMOUNT', 'SEC.NO.OF.ACCTS',\n",
    "                'SEC.ACTIVE.ACCTS', 'SEC.OVERDUE.ACCTS', 'SEC.CURRENT.BALANCE',\n",
    "               'SEC.SANCTIONED.AMOUNT', 'SEC.DISBURSED.AMOUNT', 'PRIMARY.INSTAL.AMT',\n",
    "               'SEC.INSTAL.AMT', 'NEW.ACCTS.IN.LAST.SIX.MONTHS',\n",
    "               'DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS', 'NO.OF_INQUIRIES',\n",
    "               'Age_at_disbursaldate',   'Converted_AVERAGE.ACCT.AGE',\n",
    "               'Converted_CREDIT.HISTORY.LENGTH', 'Employment_ind','Total_verification_flags','VoterId_Pan_flag_Combo',\n",
    "           'Disbursal_Month','Disbursal_Day','PERFORM_CNS.SCORE.DESCRIPTION', 'supplier_id_ftg',\n",
    "            'branch_id_ftg','pincode_id_ftg', 'manufacturer_id_ftg',  'state_id_ftg','state_pin_code_ftg']\n",
    "#  'employee_code_id_ftg'\n",
    "\n",
    "categorical_columns = ['VoterId_Pan_flag_Combo','Disbursal_Month','Employment_ind']\n",
    "predictions1 = np.zeros(len(test_df))\n",
    "feature_importance_df = pd.DataFrame()\n",
    "start_time= time.time()\n",
    "score = [0 for _ in range(folds.n_splits)]\n",
    "oof = np.zeros(len(train_df))\n",
    "max_iter = 5\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_df.values, train_df['loan_default'].values)):\n",
    "    print(\"fold n : {}\".format(fold_))\n",
    "    \n",
    "\n",
    "  \n",
    "    train,val, test_df = creating_dfg_variables(train_df.iloc[trn_idx], train_df.iloc[val_idx], test_df)\n",
    "    \n",
    "    trn_data = lgb.Dataset(train[features],\n",
    "                           label=train_df.iloc[trn_idx]['loan_default'], categorical_feature = categorical_columns\n",
    "                          )\n",
    "    val_data = lgb.Dataset(val[features],\n",
    "                           label=train_df.iloc[val_idx]['loan_default'] , categorical_feature = categorical_columns\n",
    "                          )\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param,\n",
    "                    trn_data,\n",
    "                    num_round,\n",
    "                    valid_sets = [trn_data, val_data],\n",
    "                    verbose_eval=100,\n",
    "                    early_stopping_rounds = 100)\n",
    "    print(val_idx)\n",
    "    print(len(oof))\n",
    "    print(len(val_idx))\n",
    "    oof[val_idx] = clf.predict(val[features], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = features\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance(importance_type='gain')\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "    # we perform predictions by chunks\n",
    "    current_pred = clf.predict(test_df[features].values)\n",
    "    predictions1 += current_pred / min(folds.n_splits, max_iter)\n",
    "   \n",
    "    print(\"time elapsed: {:<5.2}min\".format((time.time() - start_time) / 60))\n",
    "    score[fold_] = roc_auc_score(train_df.iloc[val_idx]['loan_default'].values, oof[val_idx])\n",
    "    if fold_ == max_iter - 1: break\n",
    "        \n",
    "if (folds.n_splits == max_iter):\n",
    "    print(\"CV score: {:<8.5f}\".format(metrics.roc_auc_score(train_df['loan_default'].values, oof)))\n",
    "else:\n",
    "     print(\"CV score: {:<8.5f}\".format(sum(score) / max_iter))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(roc_auc_score(Y_test, final_scores))\n",
    "submission = pd.read_csv(\"C:\\\\Users\\\\Himanshu\\\\Downloads\\\\\"+test_file)\n",
    "submission['loan_default'] = predictions1\n",
    "submission[['UniqueID','loan_default']].to_csv('D3_3nd_solution.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\himanshu\\anaconda3\\lib\\site-packages (0.82)\n",
      "Requirement already satisfied: numpy in c:\\users\\himanshu\\anaconda3\\lib\\site-packages (from xgboost) (1.15.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\himanshu\\anaconda3\\lib\\site-packages (from xgboost) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combo_state_pin_ftg = pd.DataFrame(train_df.groupby(['State_ID','Current_pincode_ID'])['loan_default']\\\n",
    "                                          .apply(lambda x: x.sum()/x.count() if x.count() >=20 else 0))\\\n",
    "                                            .rename(columns = {'loan_default': 'employee_code_id_ftg'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>employee_code_id_ftg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State_ID</th>\n",
       "      <th>Current_pincode_ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"30\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>0.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.180556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.170455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.269767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.220000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.163462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.209302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.137931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.155556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.168317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.238095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.122449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.141593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.210938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.163636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.103448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.096774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.208333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.193966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">20</th>\n",
       "      <th>1552</th>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1554</th>\n",
       "      <td>0.130435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"20\" valign=\"top\">21</th>\n",
       "      <th>2913</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2914</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2916</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2917</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2919</th>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2920</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2921</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2922</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2923</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2925</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2927</th>\n",
       "      <td>0.140351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2928</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2929</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2930</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2931</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2932</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2933</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2934</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2938</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">22</th>\n",
       "      <th>544</th>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6698 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             employee_code_id_ftg\n",
       "State_ID Current_pincode_ID                      \n",
       "1        1                               0.230769\n",
       "         2                               0.180556\n",
       "         3                               0.120000\n",
       "         4                               0.170455\n",
       "         5                               0.269767\n",
       "         6                               0.220000\n",
       "         7                               0.163462\n",
       "         8                               0.209302\n",
       "         9                               0.137931\n",
       "         10                              0.000000\n",
       "         11                              0.090909\n",
       "         12                              0.100000\n",
       "         13                              0.155556\n",
       "         14                              0.168317\n",
       "         15                              0.238095\n",
       "         16                              0.122449\n",
       "         17                              0.141593\n",
       "         18                              0.210938\n",
       "         19                              0.163636\n",
       "         20                              0.000000\n",
       "         21                              0.103448\n",
       "         22                              0.000000\n",
       "         23                              0.000000\n",
       "         24                              0.142857\n",
       "         25                              0.000000\n",
       "         26                              0.125000\n",
       "         27                              0.096774\n",
       "         28                              0.000000\n",
       "         29                              0.208333\n",
       "         30                              0.193966\n",
       "...                                           ...\n",
       "20       1552                            0.176471\n",
       "         1553                            0.000000\n",
       "         1554                            0.130435\n",
       "21       2913                            0.000000\n",
       "         2914                            0.000000\n",
       "         2916                            0.000000\n",
       "         2917                            0.000000\n",
       "         2919                            0.375000\n",
       "         2920                            0.000000\n",
       "         2921                            0.000000\n",
       "         2922                            0.000000\n",
       "         2923                            0.000000\n",
       "         2925                            0.000000\n",
       "         2927                            0.140351\n",
       "         2928                            0.000000\n",
       "         2929                            0.000000\n",
       "         2930                            0.000000\n",
       "         2931                            0.000000\n",
       "         2932                            0.000000\n",
       "         2933                            0.000000\n",
       "         2934                            0.000000\n",
       "         2935                            0.000000\n",
       "         2938                            0.000000\n",
       "22       544                             0.142857\n",
       "         545                             0.000000\n",
       "         546                             0.000000\n",
       "         547                             0.000000\n",
       "         548                             0.071429\n",
       "         549                             0.000000\n",
       "         550                             0.000000\n",
       "\n",
       "[6698 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combo_state_pin_ftg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Stacking(model,train,y,test,n_fold):\n",
    "    folds=StratifiedKFold(n_splits=n_fold,random_state=1)\n",
    "    test_pred=np.empty((test.shape[0],1),float)\n",
    "    train_pred=np.empty((0,1),float)\n",
    "    for train_indices,val_indices in folds.split(train,y.values):\n",
    "        x_train,x_val=train.iloc[train_indices],train.iloc[val_indices]\n",
    "        y_train,y_val=y.iloc[train_indices],y.iloc[val_indices]\n",
    "\n",
    "        model.fit(X=x_train,y=y_train)\n",
    "        train_pred=np.append(train_pred,model.predict(x_val))\n",
    "        test_pred=np.append(test_pred,model.predict(test))\n",
    "    return test_pred.reshape(-1,1),train_pred\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
